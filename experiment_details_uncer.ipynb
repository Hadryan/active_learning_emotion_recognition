{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from custom_keras.helpers_keras import prepare_labels, build_keras_model, prepare_X\n",
    "from active_gru.my_active_learner import UncertaintyGru\n",
    "# from numpy.random import seed\n",
    "from tensorflow.keras import backend as K\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import re\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import time\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set label here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL = 'valence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "dateTimeObj = datetime.now()\n",
    "time_str = dateTimeObj.strftime(\"%H:%M_%d_%b_%y\")\n",
    "# %% markdown\n",
    "# Seed for comparable results:\n",
    "# %%\n",
    "tf.random.set_seed(22)\n",
    "# %% markdown\n",
    "# # Constants\n",
    "# %%\n",
    "INDEX_COLS = ['participant', 'sequence', 'sample']\n",
    "PATH_X_LABELLED = Path('AVEC2016', 'x_labelled.csv')\n",
    "PATH_Y_LABELLED = Path('AVEC2016', 'y_labelled.csv')\n",
    "PATH_X_POOL = Path('AVEC2016', 'x_pool.csv')\n",
    "PATH_Y_POOL = Path('AVEC2016', 'y_pool.csv')\n",
    "PATH_X_TEST = Path('AVEC2016', 'x_test.csv')\n",
    "PATH_Y_TEST = Path('AVEC2016', 'y_test.csv')\n",
    "\n",
    "\n",
    "PATH_INITIAL_WEIGHTS = os.path.join('experiment', 'init_weights_experiment.h5')\n",
    "PATH_HISTORY_RANDOM = Path('experiment', 'hist_rand_{}.pkl'.format(time_str))\n",
    "PATH_HISTORY_ACTIVE = Path('experiment', 'hist_active_{}.pkl'.format(time_str))\n",
    "PATH_HISTORY_UNCER = Path('experiment', 'hist_uncer_{}.pkl'.format(time_str))\n",
    "PATH_PLOTS = 'pictures/{}_{}_{}_querries_x_{}.png'\n",
    "\n",
    "SEQUENCE_LENGTH = 375\n",
    "SEQ_PER_QUERY = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% global variables\n",
    "X_labelled = pd.read_csv(PATH_X_LABELLED, index_col=INDEX_COLS)\n",
    "y_labelled = pd.read_csv(PATH_Y_LABELLED, index_col=INDEX_COLS)\n",
    "X_pool = pd.read_csv(PATH_X_POOL, index_col=INDEX_COLS)\n",
    "y_pool = pd.read_csv(PATH_Y_POOL, index_col=INDEX_COLS)\n",
    "X_test = pd.read_csv(PATH_X_TEST, index_col=INDEX_COLS)\n",
    "y_test = pd.read_csv(PATH_Y_TEST, index_col=INDEX_COLS)\n",
    "# %%\n",
    "\n",
    "N_FEATURES_VID = X_labelled.filter(regex='vid', axis=1).shape[-1]\n",
    "N_FEATURES_AUD = X_labelled.filter(regex='aud', axis=1).shape[-1]\n",
    "pool_size = 25\n",
    "y_labelled = y_labelled['y_{}'.format(LABEL)]\n",
    "y_pool = y_pool['y_{}'.format(LABEL)]\n",
    "y_test = y_test['y_{}'.format(LABEL)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labelled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pickle(path: str):\n",
    "    return pickle.load(open(path, 'rb'))\n",
    "\n",
    "\n",
    "def dump_pickle(history: object, path: str):\n",
    "    pickle.dump(history, open(path, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_mc_drop(x, n_pool, model_mc_d, model_def, sequence_length, t=100):\n",
    "    \"\"\"Return normal predictions and MC dropout predictions\"\"\"\n",
    "    # outlier scores:\n",
    "    # use model to make predictions\n",
    "    X_aud_3d = prepare_X(x, 'aud', sequence_length)\n",
    "    X_vid_3d = prepare_X(x, 'vid', sequence_length)\n",
    "\n",
    "    # uncertainty scores\n",
    "    # predictions: m_instances * labels_per_sequence *\n",
    "    # number of predictions (t) * different_labels_predicted\n",
    "    predictions_mc = np.zeros(\n",
    "        (X_aud_3d.shape[0], X_aud_3d.shape[1] // n_pool, t))\n",
    "    for j in range(t):\n",
    "        pred_curr = model_mc_d.predict([X_aud_3d, X_vid_3d])\n",
    "        predictions_mc[:, :, j] = pred_curr.squeeze(axis=-1)\n",
    "        # drop the last axis, which is just of dim 1 anyway\n",
    "        # variance along the axis 2 (different dropout predictions)\n",
    "        # mean per sequence (axis 1)\n",
    "    pred = model_def.predict([X_aud_3d, X_vid_3d])\n",
    "    return predictions_mc, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_pred_vs_label(y, pred):\n",
    "    \"\"\"plot label vs model output.\"\"\"\n",
    "    cols = 2\n",
    "    fig, ax = plt.subplots(y.shape[0] // cols + 1, cols, figsize=(20, 200))\n",
    "    counter = 0\n",
    "    for row in range(y.shape[0] // cols):\n",
    "        for col in range(cols):\n",
    "            ax[row, col].plot(y[counter], label='label')\n",
    "            ax[row, col].plot(pred[counter], label='prediction')\n",
    "            ax[row, col].set(title='seq_{}'.format(counter),\n",
    "                             xlabel='time_step',\n",
    "                             ylabel='label/prediction')\n",
    "            ax[row, col].set_ylim([-0.5, 0.5])\n",
    "            ax[row, col].legend()\n",
    "            counter += 1\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_stats(eval_x_labelled=True):\n",
    "    \"\"\"Compute stats and return as pandas df.\"\"\"\n",
    "    if eval_x_labelled:\n",
    "        x_chosen = uncert_learner.x_labelled\n",
    "        y_chosen = uncert_learner.y_labelled\n",
    "    else:\n",
    "        x_chosen = uncert_learner.x_pool\n",
    "        y_chosen = uncert_learner.y_pool\n",
    "    preds_mc, pred = comp_mc_drop(x_chosen, uncert_learner.n_pool,\n",
    "                                  uncert_learner.model_dropout_test,\n",
    "                                  uncert_learner.model, SEQUENCE_LENGTH)\n",
    "    pred_mc = preds_mc.mean(axis=-1)\n",
    "    pred = pred.squeeze()\n",
    "    var = preds_mc.var(axis=-1)\n",
    "    y = prepare_labels(y_chosen, SEQUENCE_LENGTH, pool_size).squeeze(axis=-1)\n",
    "    error_mc = np.abs(y - pred_mc)\n",
    "    error_def = np.abs(y - pred)\n",
    "    sample_idx = np.array([np.arange(y.shape[1]) for i in range(y.shape[0])\n",
    "                           ]).astype(np.int).reshape(-1, 1)\n",
    "    stats_df = pd.DataFrame(\n",
    "        data=np.concatenate(\n",
    "            [\n",
    "                # sample_idx,\n",
    "                y.reshape(-1, 1),\n",
    "                pred.reshape(-1, 1),\n",
    "                pred_mc.reshape(-1, 1),\n",
    "                var.reshape(-1, 1),\n",
    "                error_mc.reshape(-1, 1),\n",
    "                error_def.reshape(-1, 1)\n",
    "            ],\n",
    "            axis=1),\n",
    "        columns=[\n",
    "            'label', 'pred', 'pred_mc', 'var_mc', 'error_mc', 'error_default'\n",
    "        ])\n",
    "    stats_df = stats_df.astype(np.float)\n",
    "    return stats_df, y, pred, preds_mc.reshape(-1, preds_mc.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mc(df_stats, preds_mc, label='arousal'):\n",
    "    \"\"\"Histograms of stochastic forward passes of MC dropout.\"\"\"\n",
    "    # numpy.argsort(data)[len(data)//2]\n",
    "    idx_median_err = df_stats['error_mc'].to_numpy().argsort()[\n",
    "        df_stats['error_mc'].shape[0] // 2]\n",
    "    idx_max_err = df_stats['error_mc'].idxmax()\n",
    "    idx_min_err = df_stats['error_mc'].idxmin()\n",
    "    idx_median_label = df_stats['label'].to_numpy().argsort()[\n",
    "        df_stats['label'].shape[0] // 2]\n",
    "    idx_max_label = df_stats['label'].idxmax()\n",
    "    idx_min_label = df_stats['label'].idxmin()\n",
    "\n",
    "    indices = [[idx_min_err, idx_median_err, idx_max_err],\n",
    "               [idx_min_label, idx_median_label, idx_max_label]]\n",
    "    titles = [[\n",
    "        'lowest prediction error', 'approx. median prediction error',\n",
    "        'highest prediction error'\n",
    "    ], ['minimum label', 'approx. median label', 'maximum label']]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 8))\n",
    "    for i in range(2):\n",
    "        for j in range(3):\n",
    "            sns.distplot(preds_mc[indices[i][j]],\n",
    "                         ax=axes[i][j],\n",
    "                         color='green',\n",
    "                         label='MC dropout')\n",
    "            axes[i][j].axvline(x=df_stats.loc[indices[i][j], 'pred_mc'],\n",
    "                               label='MC prediction')\n",
    "            axes[i][j].axvline(x=df_stats.loc[indices[i][j], 'label'],\n",
    "                               label='label {}'.format(label),\n",
    "                               color='orange')\n",
    "            axes[i][j].legend()\n",
    "            axes[i][j].set(title=titles[i][j],\n",
    "                           xlabel='predicted label',\n",
    "                           ylabel='density')\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_plots_mc(df_stats, label='arousal'):\n",
    "    \"\"\"scatter plots of some interesting variables.\"\"\"\n",
    "    fig, axes = plt.subplots(1, 4, figsize=(15, 5))\n",
    "    sns.distplot(df_stats['var_mc'], ax=axes[0])\n",
    "    axes[0].set(title='histogram variance MC dropout',\n",
    "                ylabel='density',\n",
    "                xlabel='variance MC dropout')\n",
    "    sns.scatterplot(data=df_stats, x='var_mc', y='error_mc', ax=axes[1])\n",
    "    axes[1].set(title='variance MC dropout vs. prediction error',\n",
    "                xlabel='variance MC dropout',\n",
    "                ylabel='prediction error')\n",
    "    axes[1].set_xlim(left=-0.005, auto=True)\n",
    "    sns.scatterplot(data=df_stats, x='pred_mc', y='label', ax=axes[2])\n",
    "    axes[2].set(title='prediction vs. true label',\n",
    "                xlabel='prediction MC',\n",
    "                ylabel='label {}'.format(label))\n",
    "    sns.scatterplot(data=df_stats, x='label', y='error_mc', ax=axes[3])\n",
    "    axes[3].set(title='label vs. prediction error'.format(label),\n",
    "                ylabel='prediction error',\n",
    "                xlabel='label {}'.format(label))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Uncertainty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uncert = build_keras_model(SEQUENCE_LENGTH,\n",
    "                                 N_FEATURES_AUD,\n",
    "                                 N_FEATURES_VID,\n",
    "                                 pool_size=pool_size,\n",
    "                                 n_neurons_gru=64,\n",
    "                                 n_neurons_hid_aud=44,\n",
    "                                 n_neurons_hid_vid=100,\n",
    "                                 dropout_rate=0.38,\n",
    "                                 rec_dropout_rate=0.04,\n",
    "                                 rec_l2=0,\n",
    "                                 ker_l2=0)\n",
    "\n",
    "model_uncert_drop = build_keras_model(\n",
    "    SEQUENCE_LENGTH,\n",
    "    N_FEATURES_AUD,\n",
    "    N_FEATURES_VID,\n",
    "    pool_size=pool_size,\n",
    "    n_neurons_gru=64,\n",
    "    n_neurons_hid_aud=44,\n",
    "    n_neurons_hid_vid=100,\n",
    "    dropout_rate=0.38,\n",
    "    rec_dropout_rate=0.04,\n",
    "    rec_l2=0,\n",
    "    ker_l2=0,\n",
    "    training_mode=True,\n",
    ")\n",
    "# new uncert learner object\n",
    "uncert_learner = UncertaintyGru(X_pool,\n",
    "                                y_pool,\n",
    "                                model_uncert,\n",
    "                                model_uncert_drop,\n",
    "                                SEQUENCE_LENGTH,\n",
    "                                pool_size,\n",
    "                                X_test,\n",
    "                                y_test,\n",
    "                                X_labelled,\n",
    "                                y_labelled,\n",
    "                                t=100)\n",
    "\n",
    "# reset weights of model\n",
    "uncert_learner.model.save_weights(PATH_INITIAL_WEIGHTS)\n",
    "uncert_learner.model_dropout_test.load_weights(PATH_INITIAL_WEIGHTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train on x_labelled at t_0:\n",
    "uncert_learner.train_x_labelled(epochs=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'mae', 'neg_ccc']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uncert_learner.model.metrics_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot details for different number of queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_PLOTS_MC = 'pictures/{}_mc_predictions_{}_querries.png'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform active leaning and plot statistics at different stages, as X_labelled grows and X_pool shrinks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queried seqs: 20\n",
      "Correlation MC var - predicition errorr pearsons r : 0.004034555724689486, p: 0.8234652140589979\n",
      "queried seqs: 40\n",
      "Correlation MC var - predicition errorr pearsons r : 0.042111169297716244, p: 0.026944630181244482\n",
      "queried seqs: 60\n",
      "Correlation MC var - predicition errorr pearsons r : 0.03361129029301091, p: 0.0955761826717641\n",
      "queried seqs: 80\n",
      "Correlation MC var - predicition errorr pearsons r : 0.017956041066238014, p: 0.40422150861000095\n",
      "queried seqs: 100\n",
      "Correlation MC var - predicition errorr pearsons r : 0.04915234777234231, p: 0.03403264171495935\n",
      "queried seqs: 120\n",
      "Correlation MC var - predicition errorr pearsons r : 0.07240887820920641, p: 0.004217936499216891\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "for i in range(6):\n",
    "    x_labelled_new, y_labelled_new = uncert_learner.query_sequences(20)\n",
    "    # train model\n",
    "    uncert_learner.train_x_labelled(epochs=8)\n",
    "    uncert_learner.evaluate_on_test_set()\n",
    "    stats_x_labelled, y_labelled, pred_y_labelled, preds_mc_labelled = comp_stats(\n",
    "    )\n",
    "    # over/ under fitting\n",
    "    # performance on x_labelled\n",
    "    y_3d_l = prepare_labels(uncert_learner.y_labelled, uncert_learner.sequence_length, uncert_learner.n_pool)\n",
    "    X_aud_3d_l = prepare_X(uncert_learner.x_labelled, 'aud', uncert_learner.sequence_length)\n",
    "    X_vid_3d_l = prepare_X(uncert_learner.x_labelled, 'vid', uncert_learner.sequence_length)\n",
    "    loss_l = uncert_learner.model.evaluate([X_aud_3d_l, X_vid_3d_l], y_3d_l, verbose=0)\n",
    "    # performance on x_pool\n",
    "    y_3d_p = prepare_labels(uncert_learner.y_pool, uncert_learner.sequence_length, uncert_learner.n_pool)\n",
    "    X_aud_3d_p = prepare_X(uncert_learner.x_pool, 'aud', uncert_learner.sequence_length)\n",
    "    X_vid_3d_p = prepare_X(uncert_learner.x_pool, 'vid', uncert_learner.sequence_length)\n",
    "    loss_p = uncert_learner.model.evaluate([X_aud_3d_p, X_vid_3d_p], y_3d_p, verbose=0)\n",
    "    loss = loss_l + loss_p\n",
    "    losses.append(loss)                       \n",
    "    # on x_labelled general statistics\n",
    "    fig_stats_labelled = scatter_plots_mc(stats_x_labelled, label=LABEL)\n",
    "    fig_stats_labelled.savefig(\n",
    "        PATH_PLOTS.format(LABEL, 'stats', uncert_learner.queried_seq_tot,\n",
    "                          'labelled'))\n",
    "    #\n",
    "    pred_vs_label_lab = plot_pred_vs_label(y_labelled, pred_y_labelled)\n",
    "    pred_vs_label_lab.savefig(\n",
    "        PATH_PLOTS.format(LABEL, 'preds', uncert_learner.queried_seq_tot,\n",
    "                          'labelled'))\n",
    "    # on x_pool general statistics\n",
    "    stats_x_pool, y_pool, pred_y_pool, preds_mc_pool = comp_stats(\n",
    "        eval_x_labelled=False)\n",
    "    fig_stats_pool = scatter_plots_mc(stats_x_pool, label=LABEL)\n",
    "    fig_stats_pool.savefig(\n",
    "        PATH_PLOTS.format(LABEL, 'stats', uncert_learner.queried_seq_tot,\n",
    "                          'pool'))\n",
    "\n",
    "    pred_vs_label_pool = plot_pred_vs_label(y_pool, pred_y_pool)\n",
    "    pred_vs_label_pool.savefig(\n",
    "        PATH_PLOTS.format(LABEL, 'preds', uncert_learner.queried_seq_tot,\n",
    "                          'pool'))\n",
    "\n",
    "    # lower level MC prediction plots on x_pool\n",
    "    fig_mc_pool = plot_mc(stats_x_pool, preds_mc_pool, label=LABEL)\n",
    "    fig_mc_pool.savefig(\n",
    "        PATH_PLOTS_MC.format(LABEL, uncert_learner.queried_seq_tot))\n",
    "\n",
    "    # print correlation\n",
    "    print('queried seqs: {}'.format(uncert_learner.queried_seq_tot))\n",
    "    r, p = pearsonr(stats_x_pool['error_default'], stats_x_pool['var_mc'])\n",
    "    print('Correlation MC var - predicition error \\br pearsons r : {}, p: {}'.\n",
    "          format(r, p))\n",
    "    plt.close(fig='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_losses = pd.DataFrame(data=np.array(losses), columns=['labelled loss', 'labelled_mae', 'labelled_neg_ccc', 'pool loss', 'pool_mae', 'pool_neg_ccc']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labelled loss</th>\n",
       "      <th>labelled_mae</th>\n",
       "      <th>labelled_neg_ccc</th>\n",
       "      <th>pool loss</th>\n",
       "      <th>pool_mae</th>\n",
       "      <th>pool_neg_ccc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.077992</td>\n",
       "      <td>0.036188</td>\n",
       "      <td>0.093411</td>\n",
       "      <td>0.865974</td>\n",
       "      <td>0.105983</td>\n",
       "      <td>0.874507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.026977</td>\n",
       "      <td>0.021966</td>\n",
       "      <td>0.027851</td>\n",
       "      <td>0.745825</td>\n",
       "      <td>0.103358</td>\n",
       "      <td>0.750590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.164709</td>\n",
       "      <td>0.065802</td>\n",
       "      <td>0.193190</td>\n",
       "      <td>0.785723</td>\n",
       "      <td>0.101852</td>\n",
       "      <td>0.804433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.015479</td>\n",
       "      <td>0.017504</td>\n",
       "      <td>0.015479</td>\n",
       "      <td>0.766385</td>\n",
       "      <td>0.097193</td>\n",
       "      <td>0.760919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.183821</td>\n",
       "      <td>0.067742</td>\n",
       "      <td>0.188213</td>\n",
       "      <td>0.824194</td>\n",
       "      <td>0.096883</td>\n",
       "      <td>0.824195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013129</td>\n",
       "      <td>0.016164</td>\n",
       "      <td>0.014382</td>\n",
       "      <td>0.776075</td>\n",
       "      <td>0.091644</td>\n",
       "      <td>0.823511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labelled loss  labelled_mae  labelled_neg_ccc  pool loss  pool_mae  \\\n",
       "0       0.077992      0.036188          0.093411   0.865974  0.105983   \n",
       "1       0.026977      0.021966          0.027851   0.745825  0.103358   \n",
       "2       0.164709      0.065802          0.193190   0.785723  0.101852   \n",
       "3       0.015479      0.017504          0.015479   0.766385  0.097193   \n",
       "4       0.183821      0.067742          0.188213   0.824194  0.096883   \n",
       "5       0.013129      0.016164          0.014382   0.776075  0.091644   \n",
       "\n",
       "   pool_neg_ccc  \n",
       "0      0.874507  \n",
       "1      0.750590  \n",
       "2      0.804433  \n",
       "3      0.760919  \n",
       "4      0.824195  \n",
       "5      0.823511  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.176489"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1-0.823511"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
